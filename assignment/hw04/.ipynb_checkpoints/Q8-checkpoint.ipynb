{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the logistic function\n",
    "def logistic_func(theta, x):\n",
    "    t = x.T @ theta\n",
    "    g = np.zeros(t.shape)\n",
    "    # split into positive and negative to improve stability\n",
    "    g[t>=0.0] = 1.0 / (1.0 + np.exp(-t[t>=0.0])) \n",
    "    g[t<0.0] = np.exp(t[t<0.0]) / (np.exp(t[t<0.0])+1.0)\n",
    "    return g\n",
    "\n",
    "# function to compute output of LR classifier\n",
    "def lr_predict(theta,x):\n",
    "    # form Xtilde for prediction\n",
    "    x = np.vstack((x.T , np.ones(x.shape[0])) )\n",
    "    return logistic_func(theta,x)\n",
    "\n",
    "# function to evaluate objective function (-f)\n",
    "def f_eval(theta, x, y):\n",
    "    t = x.T @ theta\n",
    "    return -np.vdot(t,y) + np.sum(np.log(1+np.exp(t)))\n",
    "\n",
    "# function to compute the gradient of -f\n",
    "def grad(theta, x, y):\n",
    "    g = logistic_func(theta,x)\n",
    "    return -(x @ (y-g))\n",
    "\n",
    "def hessian(theta, x):\n",
    "    g = logistic_func(theta, x)\n",
    "    n = g.shape[0]\n",
    "    return np.dot(np.dot(np.dot(x, np.diag(g.reshape(n))), np.diag(1-g.reshape(n))), x.T)\n",
    "    \n",
    "    \n",
    "# gradient descent\n",
    "# returns theta and number of iterations\n",
    "def gradDesc(x, y, alpha, c, rho, delta, maxiter, backTracking=False):\n",
    "    # Initialization\n",
    "    theta = np.zeros(x.shape[0])\n",
    "    d = -grad(theta, x, y) # 3*1\n",
    "    k = 0\n",
    "    inner = 0\n",
    "    while (k < maxiter) and (np.linalg.norm(d) > delta):\n",
    "        '''\n",
    "        this is backtracking tragetegy, Or should I say: Strategy :)\n",
    "        '''\n",
    "        if backTracking:\n",
    "            alpha, m = back_tracking(x, y, theta, d, alpha, c, rho)\n",
    "            if m != 0:\n",
    "                print('optimal and total number of iterations is {} and {}'.format(alpha, m))\n",
    "        theta = theta + alpha * d\n",
    "        d = -grad(theta, x, y)\n",
    "        k = k + 1\n",
    "        if backTracking:\n",
    "            inner = inner + m\n",
    "    total = k + inner\n",
    "    return theta, k, total\n",
    "\n",
    "\n",
    "# heavy ball method\n",
    "# returns theta and number of iterations\n",
    "def heavyBall(x, y, alpha, beta, c, rho, delta, maxiter, backTracking=False):\n",
    "    # Initialization\n",
    "    theta = [np.zeros(x.shape[0]), np.zeros(x.shape[0])]\n",
    "    d = -grad(theta[-1], x, y) # 3*1\n",
    "    k = 1\n",
    "    inner = 0\n",
    "    while (k < maxiter) and (np.linalg.norm(d) > delta):\n",
    "        '''\n",
    "        this is backtracking tragetegy, Or should I say: Strategy :)\n",
    "        '''\n",
    "        if backTracking:\n",
    "            alpha, m = back_tracking(x, y, theta[-1], d, alpha, c, rho)\n",
    "            if m != 0:\n",
    "                print('optimal and total number of iterations is {} and {}'.format(alpha, m))           \n",
    "        theta.append(theta[k] + alpha * d + beta * (theta[k] - theta[k-1]))\n",
    "        d = -grad(theta[-1], x, y)\n",
    "        k = k + 1\n",
    "        if backTracking:\n",
    "            inner = inner + m\n",
    "    total = k + inner\n",
    "    return theta[-1], k-1, total-1\n",
    "\n",
    "\n",
    "\n",
    "# nesterov's method\n",
    "# returns theta and number of iterations\n",
    "def nesterov(x, y, alpha, c, rho, delta, maxiter, backTracking=False):\n",
    "    # Initialization\n",
    "    theta = [np.zeros(x.shape[0]), np.zeros(x.shape[0])]\n",
    "    d = -grad(theta[-1], x, y) # 3*1\n",
    "    k = 1\n",
    "    p = 0\n",
    "    inner = 0\n",
    "    while (k < maxiter) and (np.linalg.norm(d) > delta):\n",
    "        '''\n",
    "        this is backtracking tragetegy, Or should I say: Strategy :)\n",
    "        '''\n",
    "        if backTracking:\n",
    "            alpha, m = back_tracking(x, y, theta[-1], d, alpha, c, rho)\n",
    "            if m != 0:\n",
    "                print('optimal and total number of iterations is {} and {}'.format(alpha, m))\n",
    "        theta.append(theta[k] + alpha * d + p)\n",
    "        k = k + 1\n",
    "        beta = (k - 1) / (k + 2)\n",
    "        p = beta * (theta[-1] - theta[-2])\n",
    "        d = -grad(theta[-1] + p, x, y)\n",
    "        if backTracking:\n",
    "            inner = inner + m\n",
    "    total = k + inner\n",
    "    return theta[-1], k-1, total-1\n",
    "\n",
    "\n",
    "\n",
    "# newton's method\n",
    "# returns theta and number of iterations\n",
    "def newton(x, y, alpha, c, rho, delta, maxiter, backTracking=False):\n",
    "    # Initialization\n",
    "    theta = np.zeros(x.shape[0])\n",
    "    d = np.linalg.inv(hessian(theta, x)) @ (-grad(theta, x, y)) # 3*1\n",
    "    k = 0\n",
    "    inner = 0\n",
    "    while (k < maxiter) and (np.linalg.norm(d) > delta):\n",
    "        '''\n",
    "        this is backtracking tragetegy, Or should I say: Strategy :)\n",
    "        '''\n",
    "        if backTracking:\n",
    "            alpha, m = back_tracking(x, y, theta, d, alpha, c, rho)\n",
    "            if m != 0:\n",
    "                print('optimal and total number of iterations is {} and {}'.format(alpha, m))\n",
    "        theta = theta + alpha * d\n",
    "        d = np.linalg.inv(hessian(theta, x)) @ (-grad(theta, x, y))\n",
    "        k = k + 1\n",
    "        if backTracking:\n",
    "            inner = inner + m\n",
    "    total = inner + k\n",
    "    return theta, k, total\n",
    "\n",
    "\n",
    "\n",
    "def bfgs(x, y, alpha, c, rho, delta, maxiter, backTracking=False):\n",
    "    # Initialization\n",
    "    theta = [np.zeros(x.shape[0])]\n",
    "    H = np.eye(3) # 3*3\n",
    "    k = 0\n",
    "    inner = 0\n",
    "    gd = [grad(theta[0], x, y)]\n",
    "    \n",
    "    d = np.dot(H, -gd[-1])\n",
    "    while k < maxiter and (np.linalg.norm(d) > delta):\n",
    "        '''\n",
    "        this is backtracking tragetegy, Or should I say: Strategy :)\n",
    "        '''\n",
    "        d = -1 * np.dot(H, gd[-1])\n",
    "        if backTracking:\n",
    "            alpha, m = back_tracking(x, y, theta[-1], gd[-1], alpha, c, rho)\n",
    "            if m != 0:\n",
    "                print('optimal and total number of iterations is {} and {}'.format(alpha, m))\n",
    "                \n",
    "        theta.append(theta[-1] + alpha * d)\n",
    "        gd.append(grad(theta[-1], x, y))\n",
    "        s = theta[-1] - theta[-2] # 3*1\n",
    "        y_bfgs = gd[-1] - gd[-2] # 3*1\n",
    "        a = np.dot(H, y_bfgs) # 3*1\n",
    "\n",
    "        gamma = np.dot(s.T, y_bfgs) # scalar\n",
    "        print(gamma)\n",
    "        H = H + ((gamma + np.dot(y_bfgs.T, a))/(gamma**2)) * np.dot(s, s.T) - (1/gamma) * np.dot(a, s.T) -(1/gamma) * np.dot(s, a.T)\n",
    "        k = k + 1\n",
    "        if backTracking:\n",
    "            inner = inner + m\n",
    "        print(theta[-1])\n",
    "    total = k + inner\n",
    "    return theta[-1], k, total\n",
    "\n",
    "\n",
    "\n",
    "# back_tracking\n",
    "# returns alpha\n",
    "def back_tracking(x,y,theta,d,alpha,c,rho):\n",
    "    '''\n",
    "    Phi function, see notes\n",
    "    '''\n",
    "    def phi(alpha):\n",
    "        return f_eval(theta + alpha * d, x, y)\n",
    "    '''\n",
    "    h function, see notes\n",
    "    '''\n",
    "    def h(alpha):\n",
    "        return f_eval(theta, x, y) + c * alpha * (d.T @ d)\n",
    "    '''\n",
    "    backtracking\n",
    "    '''\n",
    "    m = 0\n",
    "    while phi(alpha) > h(alpha):\n",
    "        alpha = rho * alpha\n",
    "        m += 1\n",
    "    return alpha, m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate dataset    \n",
    "np.random.seed(2020) # Set random seed so results are repeatable\n",
    "x,y = datasets.make_blobs(n_samples=100,n_features=2,centers=2,cluster_std=6.0)\n",
    "\n",
    "# Form Xtilde\n",
    "x = np.vstack((x.T , np.ones(x.shape[0])) ) #3*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal and total number of iterations is 0.004000000000000001 and 3\n",
      "Number of iterations required (Gradient Descent): 962\n",
      "Number of iterations required (Gradient Descent Combined backtracking): 965\n",
      "Solution: [-0.28086922947048915 -0.45756681602146676 2.2134228557652382]^T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gexueren/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "x: np.array\n",
    "y: np.array\n",
    "alpha: float\n",
    "c: float 1e-4 - 0.3\n",
    "rho: float 0.1 - 0.8\n",
    "delta: float\n",
    "maxiter: int\n",
    "backTracking: bool, default: False\n",
    "'''\n",
    "theta_gd, num_iters, total = gradDesc(x, y, 0.5, 0.1, 0.2, 1e-3, 10000, False)\n",
    "theta_gd, num_iters, total = gradDesc(x, y, 0.5, 0.1, 0.2, 1e-3, 10000, True)\n",
    "print('Number of iterations required (Gradient Descent): {0}'.format(num_iters))\n",
    "print('Number of iterations required (Gradient Descent Combined backtracking): {0}'.format(total))\n",
    "print('Solution: [{0} {1} {2}]^T'.format(theta_gd[0], theta_gd[1], theta_gd[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heavy Ball Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal and total number of iterations is 0.0020000000000000005 and 3\n",
      "Number of iterations required (Heavy Ball Method): 210\n",
      "Number of iterations required (Gradient Descent Combined backtracking): 213\n",
      "Solution: [-0.28090233848756674 -0.4576125163504644 2.2138087539926894]^T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gexueren/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "x: np.array\n",
    "y: np.array\n",
    "alpha: float\n",
    "beta: float\n",
    "c: float\n",
    "rho: float\n",
    "delta: float\n",
    "maxiter: int\n",
    "backTracking: bool, default: False\n",
    "'''\n",
    "\n",
    "# theta_hbm, num_iters = heavyBall(x, y, 0.001, 0.95, 0.1, 0.2, 1e-3, 10000, False)\n",
    "# theta_hbm, num_iters = heavyBall(x, y, 0.001, 0.9, 0.1, 0.2, 1e-3, 10000, False)\n",
    "theta_hbm, num_iters, total = heavyBall(x, y, 0.25, 0.9, 0.1, 0.2, 1e-3, 10000, True)\n",
    "print('Number of iterations required (Heavy Ball Method): {0}'.format(num_iters))\n",
    "print('Number of iterations required (Gradient Descent Combined backtracking): {0}'.format(total))\n",
    "print('Solution: [{0} {1} {2}]^T'.format(theta_hbm[0], theta_hbm[1], theta_hbm[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nesterov's method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal and total number of iterations is 0.004000000000000001 and 3\n",
      "optimal and total number of iterations is 0.0008000000000000003 and 1\n",
      "Number of iterations required (Nesterov's Method): 162\n",
      "Number of iterations required (Gradient Descent Combined backtracking): 166\n",
      "Solution: [-0.28122598034923835 -0.4580532065467381 2.2175508597052973]^T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gexueren/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "x: np.array\n",
    "y: np.array\n",
    "alpha: float\n",
    "c: float\n",
    "rho: float\n",
    "delta: float\n",
    "maxiter: int\n",
    "backTracking: bool, default: False\n",
    "'''\n",
    "\n",
    "\n",
    "# theta_nm, num_iters, total = nesterov(x, y, 0.001, 0.1, 0.2, 1e-3, 10000, False)\n",
    "theta_nm, num_iters, total = nesterov(x, y, 0.5, 0.1, 0.2, 1e-3, 10000, True)\n",
    "print('Number of iterations required (Nesterov\\'s Method): {0}'.format(num_iters))\n",
    "print('Number of iterations required (Gradient Descent Combined backtracking): {0}'.format(total))\n",
    "print('Solution: [{0} {1} {2}]^T'.format(theta_nm[0], theta_nm[1], theta_nm[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newton's method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations required (Newton's method): 6\n",
      "Number of iterations required (Gradient Descent Combined backtracking): 6\n",
      "Solution: [-0.28087302535408804 -0.45755993255549 2.2135573728358855]^T\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "x: np.array\n",
    "y: np.array\n",
    "alpha: float\n",
    "c: float\n",
    "rho: float\n",
    "delta: float\n",
    "maxiter: int\n",
    "backTracking: bool, default: False\n",
    "'''\n",
    "# theta_Nm, num_iters, total = newton(x, y, 1.0, 0.1, 0.2, 1e-3, 10000, False)\n",
    "theta_Nm, num_iters, total = newton(x, y, 1.0, 0.1, 0.2, 1e-3, 10000, True)\n",
    "print('Number of iterations required (Newton\\'s method): {0}'.format(num_iters))\n",
    "print('Number of iterations required (Gradient Descent Combined backtracking): {0}'.format(total))\n",
    "print('Solution: [{0} {1} {2}]^T'.format(theta_Nm[0], theta_Nm[1], theta_Nm[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal and total number of iterations is 2.684354560000004e-20 and 28\n",
      "1.2557626617743033e-30\n",
      "[-7.25198225e-18 -7.41981406e-18  0.00000000e+00]\n",
      "1.0002829729240346e-30\n",
      "[-1.34292010e-18 -1.67858372e-18  1.31610444e-17]\n",
      "1.4084356290875006e-29\n",
      "[-4.19467963e-17 -4.24502918e-17 -2.01908496e-17]\n",
      "optimal and total number of iterations is 5.368709120000009e-21 and 1\n",
      "8.147182784655809e-31\n",
      "[-2.82074694e-17 -2.87445312e-17 -5.00112616e-18]\n",
      "8.052665320529447e-30\n",
      "[-6.27031021e-17 -6.32737303e-17 -3.80463625e-17]\n",
      "3.4643081598669256e-29\n",
      "[3.67767067e-18 3.07347617e-18 2.97848068e-17]\n",
      "1.0343135557424667e-28\n",
      "[-1.31882396e-16 -1.32520157e-16 -1.04324864e-16]\n",
      "4.261328558914979e-28\n",
      "[1.36605844e-16 1.35934517e-16 1.65613773e-16]\n",
      "1.8043460847067443e-27\n",
      "[-4.03128573e-16 -4.03833466e-16 -3.72670247e-16]\n",
      "7.074034939363882e-27\n",
      "[6.73654633e-16 6.72916173e-16 7.05563355e-16]\n",
      "2.8201524873859597e-26\n",
      "[-1.48262383e-15 -1.48339586e-15 -1.44926471e-15]\n",
      "1.1322407440170505e-25\n",
      "[2.82721654e-15 2.82641095e-15 2.86202606e-15]\n",
      "4.53042381431726e-25\n",
      "[-5.79517192e-15 -5.79601108e-15 -5.75891201e-15]\n",
      "1.815772677998629e-24\n",
      "[1.14468955e-14 1.14460227e-14 1.14846058e-14]\n",
      "7.273475010532778e-24\n",
      "[-2.30399508e-14 -2.30408571e-14 -2.30007901e-14]\n",
      "2.9089082072667414e-23\n",
      "[4.59310332e-14 4.59300934e-14 4.59716443e-14]\n",
      "1.1631949814521874e-22\n",
      "[-9.20136428e-14 -9.20146163e-14 -9.19715813e-14]\n",
      "4.651324058995842e-22\n",
      "[1.83873000e-13 1.83871993e-13 1.83916512e-13]\n",
      "1.8604752924136588e-21\n",
      "[-3.67902995e-13 -3.67904036e-13 -3.67858033e-13]\n",
      "7.441876288157528e-21\n",
      "[7.35646287e-13 7.35645213e-13 7.35692700e-13]\n",
      "2.9767789171906496e-20\n",
      "[-1.47145499e-12 -1.47145609e-12 -1.47140712e-12]\n",
      "1.1907085769755607e-19\n",
      "[2.94274485e-12 2.94274371e-12 2.94279416e-12]\n",
      "4.762851000908639e-19\n",
      "[-5.88565753e-12 -5.88565871e-12 -5.88560677e-12]\n",
      "1.9051411213992083e-18\n",
      "[1.17711445e-11 1.17711433e-11 1.17711967e-11]\n",
      "optimal and total number of iterations is 1.0737418240000018e-21 and 1\n",
      "3.0482188194457536e-19\n",
      "[4.70842316e-12 4.70842194e-12 4.70847566e-12]\n",
      "1.2192906989486903e-18\n",
      "[1.88338653e-11 1.88338641e-11 1.88339181e-11]\n",
      "4.8771644802798025e-18\n",
      "[-9.41701958e-12 -9.41702080e-12 -9.41696649e-12]\n",
      "1.9508632046432502e-17\n",
      "[4.70847497e-11 4.70847485e-11 4.70848031e-11]\n",
      "7.803450931349204e-17\n",
      "[-6.59187895e-11 -6.59187907e-11 -6.59187358e-11]\n",
      "3.121380356848812e-16\n",
      "[1.60088288e-10 1.60088287e-10 1.60088342e-10]\n",
      "1.2485521209941627e-15\n",
      "[-2.91925869e-10 -2.91925870e-10 -2.91925814e-10]\n",
      "4.994208402449635e-15\n",
      "[6.12102440e-10 6.12102438e-10 6.12102494e-10]\n",
      "1.99768340292728e-14\n",
      "[-1.19595420e-09 -1.19595420e-09 -1.19595414e-09]\n",
      "7.990733403453715e-14\n",
      "[2.42015900e-09 2.42015900e-09 2.42015906e-09]\n",
      "3.1962936471462883e-13\n",
      "[-4.81206769e-09 -4.81206769e-09 -4.81206763e-09]\n",
      "1.2785172494954377e-12\n",
      "[9.65238452e-09 9.65238452e-09 9.65238458e-09]\n",
      "5.114070647862155e-12\n",
      "[-1.92765246e-08 -1.92765246e-08 -1.92765245e-08]\n",
      "2.0456269359449262e-11\n",
      "[3.85812749e-08 3.85812749e-08 3.85812750e-08]\n",
      "8.182518329275834e-11\n",
      "[-7.71343989e-08 -7.71343989e-08 -7.71343988e-08]\n",
      "3.2729988630679095e-10\n",
      "[1.54296649e-07 1.54296649e-07 1.54296649e-07]\n",
      "1.3092063203652877e-09\n",
      "[-3.08566645e-07 -3.08566645e-07 -3.08566645e-07]\n",
      "5.236771080261346e-09\n",
      "[6.17155153e-07 6.17155153e-07 6.17155153e-07]\n",
      "2.0947517928153453e-08\n",
      "[-1.2343076e-06 -1.2343076e-06 -1.2343076e-06]\n",
      "8.378660281933533e-08\n",
      "[2.46854126e-06 2.46854126e-06 2.46854126e-06]\n",
      "3.3517416180468946e-07\n",
      "[-4.93746306e-06 -4.93746306e-06 -4.93746306e-06]\n",
      "1.3404746330035962e-06\n",
      "[9.87331915e-06 9.87331915e-06 9.87331915e-06]\n",
      "5.3636744853628e-06\n",
      "[-1.97531506e-05 -1.97531506e-05 -1.97531506e-05]\n",
      "2.144048775178143e-05\n",
      "[3.94801643e-05 3.94801643e-05 3.94801643e-05]\n",
      "8.587559142028852e-05\n",
      "[-7.9064938e-05 -7.9064938e-05 -7.9064938e-05]\n",
      "0.0003425925878596162\n",
      "[0.00015771 0.00015771 0.00015771]\n",
      "0.0013776380007843273\n",
      "[-0.0003171 -0.0003171 -0.0003171]\n",
      "0.005452244859041413\n",
      "[0.00062749 0.00062749 0.00062749]\n",
      "0.0222726777561246\n",
      "[-0.0012817 -0.0012817 -0.0012817]\n",
      "0.08534026329108856\n",
      "[0.00245574 0.00245574 0.00245574]\n",
      "0.3706039112171049\n",
      "[-0.00533595 -0.00533595 -0.00533595]\n",
      "1.239559459348072\n",
      "[0.00892754 0.00892754 0.00892754]\n",
      "6.650291807505221\n",
      "[-0.02442259 -0.02442259 -0.02442259]\n",
      "11.844887996863314\n",
      "[0.0201436 0.0201436 0.0201436]\n",
      "90.76267696560863\n",
      "[-0.12799176 -0.12799176 -0.12799176]\n",
      "1.0964225096432085\n",
      "[-0.10375746 -0.10375746 -0.10375746]\n",
      "10.176728944152833\n",
      "[-0.19240107 -0.19240107 -0.19240107]\n",
      "0.4394888105150585\n",
      "[-0.21900543 -0.21900543 -0.21900543]\n",
      "13.887701828667298\n",
      "[-0.10712031 -0.10712031 -0.10712031]\n",
      "717.733114350031\n",
      "[0.55088188 0.55088188 0.55088188]\n",
      "21606.227930900302\n",
      "[-16.26271097 -16.26271097 -16.26271097]\n",
      "0.015129550934357146\n",
      "[-19.15099572 -19.15099572 -19.15099572]\n",
      "0.07485288754538844\n",
      "[-13.37412854 -13.37412854 -13.37412854]\n",
      "0.22380717370577885\n",
      "[-24.92639013 -24.92639013 -24.92639013]\n",
      "17.10371951970651\n",
      "[-1.81746286 -1.81746286 -1.81746286]\n",
      "34.37548613199373\n",
      "[-47.69881417 -47.69881417 -47.69881417]\n",
      "119850.17720416228\n",
      "[44.74516133 44.74516133 44.74516133]\n",
      "7.59980244109137\n",
      "[2217.61134028 2217.61134028 2217.61134028]\n",
      "5634124.805615654\n",
      "[-2128.1337391 -2128.1337391 -2128.1337391]\n",
      "0.0\n",
      "[-2867.7067749 -2867.7067749 -2867.7067749]\n",
      "nan\n",
      "[nan nan nan]\n",
      "Number of iterations required (BFGS): 75\n",
      "Number of iterations required (Gradient Descent Combined backtracking): 105\n",
      "Solution: [nan nan nan]^T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gexueren/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in exp\n",
      "/Users/gexueren/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:165: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/Users/gexueren/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:165: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "x: np.array\n",
    "y: np.array\n",
    "alpha: float\n",
    "c: float\n",
    "rho: float\n",
    "delta: float\n",
    "maxiter: int\n",
    "backTracking: bool, default: False\n",
    "'''\n",
    "theta_bfgs, num_iters, total = bfgs(x, y, 1, 0.001, 0.2, 1e-3, 10000, True)\n",
    "print('Number of iterations required (BFGS): {0}'.format(num_iters))\n",
    "print('Number of iterations required (Gradient Descent Combined backtracking): {0}'.format(total))\n",
    "print('Solution: [{0} {1} {2}]^T'.format(theta_bfgs[0], theta_bfgs[1], theta_bfgs[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
