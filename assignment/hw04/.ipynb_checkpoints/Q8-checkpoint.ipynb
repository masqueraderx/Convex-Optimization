{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the logistic function\n",
    "def logistic_func(theta, x):\n",
    "    t = x.T @ theta\n",
    "    g = np.zeros(t.shape)\n",
    "    # split into positive and negative to improve stability\n",
    "    g[t>=0.0] = 1.0 / (1.0 + np.exp(-t[t>=0.0])) \n",
    "    g[t<0.0] = np.exp(t[t<0.0]) / (np.exp(t[t<0.0])+1.0)\n",
    "    return g\n",
    "\n",
    "# function to compute output of LR classifier\n",
    "def lr_predict(theta,x):\n",
    "    # form Xtilde for prediction\n",
    "    x = np.vstack((x.T , np.ones(x.shape[0])))\n",
    "    return logistic_func(theta,x)\n",
    "\n",
    "# function to evaluate objective function (-f)\n",
    "def f_eval(theta, x, y):\n",
    "    t = x.T @ theta\n",
    "    return -np.vdot(t,y) + np.sum(np.log(1+np.exp(t)))\n",
    "\n",
    "# function to compute the gradient of -f\n",
    "def grad(theta, x, y):\n",
    "    g = logistic_func(theta,x)\n",
    "    return -(x @ (y-g))\n",
    "\n",
    "def hessian(theta, x):\n",
    "    g = logistic_func(theta, x)\n",
    "    n = g.shape[0]\n",
    "    return np.dot(np.dot(np.dot(x, np.diag(g.reshape(n))), np.diag(1-g.reshape(n))), x.T)\n",
    "    \n",
    "    \n",
    "# gradient descent\n",
    "# returns theta and number of iterations\n",
    "def gradDesc(x, y, alpha=1.0, c=0.1, rho=0.2, delta=1e-3, maxiter=10000, backTracking=False):\n",
    "    # Initialization\n",
    "    theta = np.zeros(x.shape[0])\n",
    "    d = -grad(theta, x, y) # 3*1\n",
    "    k = 0\n",
    "    inner = 0\n",
    "    while (k < maxiter) and (np.linalg.norm(d) > delta):\n",
    "        '''\n",
    "        this is backtracking tragetegy, Or should I say: Strategy :)\n",
    "        '''\n",
    "        if backTracking:\n",
    "            alpha, m = back_tracking(x, y, theta, d, c, rho)\n",
    "        theta = theta + alpha * d\n",
    "        d = -grad(theta, x, y)\n",
    "        k = k + 1\n",
    "        if backTracking:\n",
    "            inner = inner + m\n",
    "    total = k + inner\n",
    "    return theta, k, total\n",
    "\n",
    "\n",
    "# heavy ball method\n",
    "# returns theta and number of iterations\n",
    "def heavyBall(x, y, alpha=1.0, beta=0.95, c=0.1, rho=0.2, delta=1e-3, maxiter=10000, backTracking=False):\n",
    "    # Initialization\n",
    "    theta = [np.zeros(x.shape[0]), np.zeros(x.shape[0])]\n",
    "    d = -grad(theta[-1], x, y) # 3*1\n",
    "    k = 1\n",
    "    inner = 0\n",
    "    while (k < maxiter) and (np.linalg.norm(d) > delta):\n",
    "        '''\n",
    "        this is backtracking tragetegy, Or should I say: Strategy :)\n",
    "        '''\n",
    "        if backTracking:\n",
    "            alpha, m = back_tracking(x, y, theta[-1], d, c, rho)      \n",
    "        theta.append(theta[k] + alpha * d + beta * (theta[k] - theta[k-1]))\n",
    "        d = -grad(theta[-1], x, y)\n",
    "        k = k + 1\n",
    "        if backTracking:\n",
    "            inner = inner + m\n",
    "    total = k + inner\n",
    "    return theta[-1], k-1, total-1\n",
    "\n",
    "\n",
    "\n",
    "# nesterov's method\n",
    "# returns theta and number of iterations\n",
    "def nesterov(x, y, alpha=1.0, c=0.1, rho=0.2, delta=1e-3, maxiter=10000, backTracking=False):\n",
    "    # Initialization\n",
    "    theta = [np.zeros(x.shape[0]), np.zeros(x.shape[0])]\n",
    "    d = -grad(theta[-1], x, y) # 3*1\n",
    "    k = 1\n",
    "    p = 0\n",
    "    inner = 0\n",
    "    while (k < maxiter) and (np.linalg.norm(d) > delta):\n",
    "        '''\n",
    "        this is backtracking tragetegy, Or should I say: Strategy :)\n",
    "        '''\n",
    "        if backTracking:\n",
    "            alpha, m = back_tracking(x, y, theta[-1], d, c, rho)\n",
    "        theta.append(theta[k] + alpha * d + p)\n",
    "        k = k + 1\n",
    "        beta = (k - 1) / (k + 2)\n",
    "        p = beta * (theta[-1] - theta[-2])\n",
    "        d = -grad(theta[-1] + p, x, y)\n",
    "        if backTracking:\n",
    "            inner = inner + m\n",
    "    total = k + inner\n",
    "    return theta[-1], k-1, total-1\n",
    "\n",
    "\n",
    "\n",
    "# newton's method\n",
    "# returns theta and number of iterations\n",
    "def newton(x, y, alpha=1.0, c=0.1, rho=0.2, delta=1e-3, maxiter=10000, backTracking=False):\n",
    "    # Initialization\n",
    "    theta = np.zeros(x.shape[0])\n",
    "    d = np.linalg.inv(hessian(theta, x)) @ (-grad(theta, x, y)) # 3*1\n",
    "    k = 0\n",
    "    inner = 0\n",
    "    while (k < maxiter) and (np.linalg.norm(d) > delta):\n",
    "        '''\n",
    "        this is backtracking tragetegy, Or should I say: Strategy :)\n",
    "        '''\n",
    "        if backTracking:\n",
    "            alpha, m = back_tracking(x, y, theta, d, c, rho)\n",
    "        theta = theta + alpha * d\n",
    "        d = np.linalg.inv(hessian(theta, x)) @ (-grad(theta, x, y))\n",
    "        k = k + 1\n",
    "        if backTracking:\n",
    "            inner = inner + m\n",
    "    total = inner + k\n",
    "    return theta, k, total\n",
    "\n",
    "\n",
    "\n",
    "# quasi-newton's method, bfgs\n",
    "# returns theta and number of iterations\n",
    "def bfgs(x, y, alpha=1.0, c=0.1, rho=0.2, delta=1e-3, maxiter=10000, backTracking=False):\n",
    "    # Initialization    \n",
    "    theta = [np.zeros(x.shape[0])]\n",
    "    h = np.eye(3)\n",
    "    g = [grad(theta[-1], x, y)]\n",
    "    d = -h @ g[-1]  \n",
    "    k = 0\n",
    "    inner = 0\n",
    "    while (k < maxiter) and (np.linalg.norm(d) > delta):\n",
    "        '''\n",
    "        this is backtracking tragetegy, Or should I say: Strategy :)\n",
    "        '''\n",
    "        if backTracking:\n",
    "            alpha, m = back_tracking(x, y, theta[-1], d, c, rho)\n",
    "        theta.append(theta[-1] + alpha * d)\n",
    "        g.append(grad(theta[-1], x, y))\n",
    "        s = np.mat(theta[-1] - theta[-2]).T\n",
    "        r = np.mat(g[-1] - g[-2]).T\n",
    "        a = h @ r\n",
    "        gamma = s.T @ r\n",
    "        # (gamma+(r.T @ a))/gamma**2 1*1 matrix\n",
    "        h = h + np.array((gamma+(r.T @ a))/gamma**2) * np.array((s @ s.T)) - np.array((a @ s.T)/gamma) - np.array((s @ a.T)/gamma)\n",
    "        d = -h @ g[-1]\n",
    "        k = k + 1\n",
    "        if backTracking:\n",
    "            inner = inner + m\n",
    "        total = inner + k\n",
    "    return theta[-1], k, total  \n",
    "\n",
    "\n",
    "# back_tracking\n",
    "# returns alpha\n",
    "def back_tracking(x, y, theta, d, c, rho):\n",
    "\n",
    "    alpha = 1.0\n",
    "    '''\n",
    "    Phi function, see notes\n",
    "    '''\n",
    "    def phi(alpha):\n",
    "        return f_eval(theta + alpha * d, x, y)\n",
    "    '''\n",
    "    h function, see notes\n",
    "    '''\n",
    "    def h(alpha):\n",
    "        return f_eval(theta, x, y) + c * alpha * (d.T @ d)\n",
    "    '''\n",
    "    backtracking\n",
    "    '''\n",
    "    m = 0\n",
    "    while phi(alpha) > h(alpha):\n",
    "        alpha = rho * alpha\n",
    "        m += 1\n",
    "    return alpha, m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate dataset    \n",
    "np.random.seed(2020) # Set random seed so results are repeatable\n",
    "x,y = datasets.make_blobs(n_samples=100,n_features=2,centers=2,cluster_std=6.0)\n",
    "\n",
    "# Form Xtilde\n",
    "x = np.vstack((x.T , np.ones(x.shape[0])) ) #3*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations required (Gradient Descent): 128\n",
      "Number of iterations required (Gradient Descent Combined backtracking): 629\n",
      "Solution: [-0.2808700476647576 -0.45756829578059527 2.213432318685843]^T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gexueren/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "x: np.array\n",
    "y: np.array\n",
    "alpha: float, default=1.0\n",
    "c: float 1e-4 - 0.3, default=0.1\n",
    "rho: float 0.1 - 0.8, default=0.2\n",
    "delta: float, default=1e-3\n",
    "maxiter: int, default=10000\n",
    "backTracking: bool, default=False\n",
    "'''\n",
    "# theta_gd, num_iters, total = gradDesc(x, y, alpha=0.0005)\n",
    "\n",
    "# if we use backtracking\n",
    "theta_gd, num_iters, total = gradDesc(x, y, c=0.1, rho=0.3, backTracking=True)\n",
    "\n",
    "print('Number of iterations required (Gradient Descent): {0}'.format(num_iters))\n",
    "print('Number of iterations required (Gradient Descent Combined backtracking): {0}'.format(total))\n",
    "print('Solution: [{0} {1} {2}]^T'.format(theta_gd[0], theta_gd[1], theta_gd[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heavy Ball Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gexueren/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations required (Heavy Ball Method): 211\n",
      "Number of iterations required (Heavy Ball Method Combined backtracking): 13064\n",
      "Solution: [-0.28090663762529855 -0.45761957993450064 2.2138432630894704]^T\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "x: np.array\n",
    "y: np.array\n",
    "alpha: float, default=1.0\n",
    "beta: float, default=0.9\n",
    "c: float, default=0.1\n",
    "rho: float, default=0.2\n",
    "delta: float, default=1e-3\n",
    "maxiter: int, default=10000\n",
    "backTracking: bool, default=False\n",
    "'''\n",
    "\n",
    "# if we set alpha=0.001 beta=0.95\n",
    "# theta_hbm, num_iters, total = heavyBall(x, y, alpha=0.001, beta=0.95)\n",
    "\n",
    "# if we set alpha=0.001 beta=0.9\n",
    "# theta_hbm, num_iters, total = heavyBall(x, y, alpha=0.001, beta=0.9)\n",
    "\n",
    "# use backtracking\n",
    "theta_hbm, num_iters, total = heavyBall(x, y, beta=0.9, c=0.01, rho=0.92, backTracking=True)\n",
    "\n",
    "print('Number of iterations required (Heavy Ball Method): {0}'.format(num_iters))\n",
    "print('Number of iterations required (Heavy Ball Method Combined backtracking): {0}'.format(total))\n",
    "print('Solution: [{0} {1} {2}]^T'.format(theta_hbm[0], theta_hbm[1], theta_hbm[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nesterov's method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations required (Nesterov's Method): 361\n",
      "Number of iterations required (Nesterov's Method Combined backtracking): 2660\n",
      "Solution: [-0.28091408440824833 -0.4576256270580674 2.2139198413771215]^T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gexueren/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "x: np.array\n",
    "y: np.array\n",
    "alpha: float, default=1.0\n",
    "c: float, default=0.1\n",
    "rho: float, default=0.2\n",
    "delta: float, default=1e-3\n",
    "maxiter: int, default=10000\n",
    "backTracking: bool, default=False\n",
    "'''\n",
    "\n",
    "# if we set alpha as 0.001\n",
    "# theta_nm, num_iters, total = nesterov(x, y, alpha=0.001)\n",
    "\n",
    "# if we use backtracking\n",
    "theta_nm, num_iters, total = nesterov(x, y, c=0.1, rho=0.4, backTracking=True)\n",
    "\n",
    "\n",
    "print('Number of iterations required (Nesterov\\'s Method): {0}'.format(num_iters))\n",
    "print('Number of iterations required (Nesterov\\'s Method Combined backtracking): {0}'.format(total))\n",
    "print('Solution: [{0} {1} {2}]^T'.format(theta_nm[0], theta_nm[1], theta_nm[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newton's method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations required (Newton's method): 6\n",
      "Number of iterations required (Newton's Method  Combined backtracking): 6\n",
      "Solution: [-0.28087302535408804 -0.45755993255549 2.2135573728358855]^T\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "x: np.array\n",
    "y: np.array\n",
    "alpha: float, default=1.0\n",
    "c: float, default=0.1\n",
    "rho: float, default=0.2\n",
    "delta: float, default=1e-3\n",
    "maxiter: int, default=10000\n",
    "backTracking: bool, default=False\n",
    "'''\n",
    "\n",
    "# if we use backtracking\n",
    "theta_Nm, num_iters, total = newton(x, y, c=0.1, rho=0.2, backTracking=True)\n",
    "\n",
    "print('Number of iterations required (Newton\\'s method): {0}'.format(num_iters))\n",
    "print('Number of iterations required (Newton\\'s Method  Combined backtracking): {0}'.format(total))\n",
    "print('Solution: [{0} {1} {2}]^T'.format(theta_Nm[0], theta_Nm[1], theta_Nm[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations required (BFGS): 10\n",
      "Number of iterations required (BFGS Combined backtracking): 18\n",
      "Solution: [-0.2808935787911126 -0.4575509599220787 2.213690581299339]^T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gexueren/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "x: np.array\n",
    "y: np.array\n",
    "alpha: float, default=1.0\n",
    "c: float, default=0.1\n",
    "rho: float, default=0.2\n",
    "delta: float, default=1e-3\n",
    "maxiter: int, default=10000\n",
    "backTracking: bool, default=False\n",
    "'''\n",
    "\n",
    "theta_bfgs, num_iters, total = bfgs(x, y, c=0.1, rho=0.2, backTracking=True)\n",
    "print('Number of iterations required (BFGS): {0}'.format(num_iters))\n",
    "print('Number of iterations required (BFGS Combined backtracking): {0}'.format(total))\n",
    "print('Solution: [{0} {1} {2}]^T'.format(theta_bfgs[0], theta_bfgs[1], theta_bfgs[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
